<!DOCTYPE html>
<html lang="en" class="scroll-smooth">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="icon" href="fav.svg" type="image/x-icon">
  <title>FrameworkZero - International Hybrid-Technical AI Governance DAO</title>
  <meta property="og:image" content="landing.jpg" />
  <meta property="og:image:width" content="600" />
  <meta property="og:image:height" content="300" />
  <meta property="og:image:alt" content="FrameworkZero - International Hybrid-Technical AI Governance DAO" />
  <script src="https://cdn.tailwindcss.com"></script>
  <link href="https://fonts.googleapis.com/css2?family=Roboto+Flex:opsz,wght@8..144,400;8..144,700&display=swap"
    rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Sansation:wght@700,400&display=swap" rel="stylesheet">
  <style>
    :root {
      --color-primary-rgb: 109, 25, 205;
      --color-secondary-rgb: 47, 38, 208;
      --color-accent-rgb: 24, 114, 200;
      --background-color-rgb: 24, 23, 38;
      --color-primary: rgba(var(--color-primary-rgb), .8);
      --color-secondary: rgba(var(--color-secondary-rgb), .8);
      --color-accent: rgba(var(--color-accent-rgb), .8);
      --background-color: rgb(var(--color-background-rgb));
    }

    .primary {
      color: var(--color-primary);
    }

    .secondary {
      color: var(--color-secondary);
    }

    .accent {
      color: var(--color-accent);
    }

    .primary-b {
      border-color: var(--color-primary);
    }

    .secondary-b {
      border-color: var(--color-secondary);
    }

    .accent-b {
      border-color: var(--color-accent);
    }

    .primary-bg {
      background-color: var(--color-primary);
    }

    .secondary-bg {
      background-color: var(--color-secondary);
    }

    .accent-bg {
      background-color: var(--color-accent);
    }

    ::selection,
    ::-moz-selection {
      background-color: var(--color-secondary) !important;
    }

    .exlink {
      text-decoration: underline 1px var(--color-accent);
    }

    .exlink::after {
      position: absolute;
      content: "⇲";
      font-size: .8em;
      transform: rotate(-90deg);
      padding-left: 2px;
    }

    .exlink:hover {
      opacity: 75%;
    }

    .tp {
      border-bottom: 2px var(--color-accent) dotted;
      cursor: pointer;
    }

    .tp:active,
    .tp:hover {
      opacity: 0.75;
    }

    #tp-container {
      background: #140527;
    }

    body {
      font-family: 'Roboto Flex', sans-serif;
      color: #e0e0e0;
      background-color: var(--background-color);
      line-height: 1.75;
      overflow-x: hidden;
    }

    canvas {
      opacity: 0.7;
    }

    #main {
      overflow-y: hidden;
      height: 100vh;
      opacity: 0;
      transition: opacity 2s ease, visibility 2s ease;
    }

    #main::before {
      content: 'Loading...';
      font-size: xx-large;
      position: fixed;
      text-align: center;
      width: 100%;
      margin-top: 5%;
      z-index: 90;
    }

    #main.show {
      height: auto;
      visibility: visible;
      opacity: 1;
    }

    #main.show::before {
      visibility: hidden;
    }

    .text-logo {
      font-family: "Sansation", sans-serif;
      font-weight: 700;
      font-style: normal;
    }

    table {
      border-radius: 1rem;
    }

    .text-gradient {
      background: linear-gradient(60deg, var(--color-primary), var(--color-secondary));
      -webkit-background-clip: text;
      -webkit-text-fill-color: transparent;
    }

    .bright {
      filter: brightness(1.5);
    }

    .content-card {
      background: #0e0e11;
      border: 1px solid #2a2844cc;
      border-radius: 0.5rem;
      position: relative;
    }

    .intro-card {
      background: #0e0e1144 !important;
      position: relative;
      overflow: hidden;
    }

    .hr-gradient {
      height: 2px;
      background: linear-gradient(90deg, transparent, var(--color-primary), var(--color-secondary), transparent);
      border: none;
    }

    .section h2,
    .section h3 {
      color: var(--color-primary);
    }

    .list-disc li::marker {
      color: var(--color-accent);
    }

    .context-menu {
      position: fixed;
      top: 1rem;
      right: 1rem;
      z-index: 100;
    }

    .menu-button {
      cursor: pointer;
      width: 3rem;
      height: 3rem;
      background-color: rgba(13, 13, 18, 0.95);
      border: 1px solid rgba(255, 255, 255, 0.2);
      border-radius: 50%;
      display: flex;
      align-items: center;
      justify-content: center;
      transition: background-color 0.3s ease;
    }

    .menu-button:hover {
      background-color: rgba(255, 255, 255, 0.025);
      border-color: var(--color-primary);
    }

    .menu-icon {
      width: 1.5rem;
      height: 1.5rem;
      stroke: #e0e0e0;
      stroke-width: 2;
      stroke-linecap: round;
      stroke-linejoin: round;
      transition: transform 0.3s ease;
    }

    .menu-button:hover .menu-icon {
      opacity: 0.7;
    }

    .menu-icon-open {
      opacity: 0.7;
    }

    .menu-list-container {
      position: absolute;
      top: 4rem;
      right: 0;
      width: 15rem;
      background-color: rgba(13, 13, 18, 0.95);
      border: 1px solid rgba(255, 255, 255, 0.1);
      border-radius: 0.5rem;
      padding: 0.5rem;
      visibility: hidden;
      opacity: 0;
      transition: opacity 0.3s ease, visibility 0.3s ease;
    }

    .menu-list-container.open {
      visibility: visible;
      opacity: 1;
    }

    .menu-list-container ul {
      list-style: none;
      margin: 0;
      padding: 0;
    }

    .menu-list-container li a {
      display: block;
      padding: 0.75rem 1rem;
      color: #e0e0e0;
      text-decoration: none;
      border-radius: 0.25rem;
      border: 1px transparent solid;
      transition: background-color 0.2s ease;
    }

    .menu-list-container li a:hover {
      background-color: rgba(255, 255, 255, 0.025);
      border-color: var(--color-primary);
    }
  </style>
</head>

<body class="bg-gray-950 text-gray-200 subpixel-antialiased">

  <!-- Canvas for the background animation -->
  <canvas id="header-canvas" class="fixed left-0 w-full h-75 z-0"></canvas>

  <div id="tp-container" class="invisible fixed bottom-0 left-0 right-0 py-6 px-6 md:px-24 z-50
      text-base text-center text-white border-t-2 secondary-b
      max-h-36 overflow-y-auto shadow-lg">
  </div>
  <hr class="fixed bottom-0 left-0 right-0 hr-gradient h-2 z-40">

  <div id="main">

    <!-- Context Menu -->
    <nav class="context-menu">
      <div class="menu-button" id="menu-button">
        <!-- New menu icon as requested -->
        <svg class="menu-icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1"
          stroke-linecap="round" stroke-linejoin="round">
          <path d="M12 2L2 7l10 5 10-5-10-5z"></path>
          <path d="M2 17l10 5 10-5M2 12l10 5 10-5"></path>
        </svg>
      </div>
      <div class="menu-list-container" id="menu-list">
        <!-- Menu items will be dynamically populated -->
        <ul></ul>
      </div>
    </nav>

    <div class="container max-w-6xl mx-auto px-4 py-12 md:px-6">

      <!-- Header Section -->
      <div class="absolute top-1 left-0 flex scale-75 pl-1 py-2 rounded-lg" style="background-color: #11111133">
        <img src="logo.svg" alt="FrameworkZero lgo" />
        <div class="-ml-4 text-logo leading-tight self-center" >
          <span class="block text-left mt-1 pr-6">
            <span class="text-gray-300 font-extrabold text-3xl md:text-4xl">Framework</span>
            <span class="text-gray-300 block -mt-3 text-2xl">Zero</span>

          </span>
        </div>
      </div>

      <header class="text-center relative h-auto flex items-center justify-center py-9 mt-6 mb-4">
        <section id="intro">

          <span class="menu-nav-target-title hidden">Introduction</span>
          <div class="relative z-10">
            <h1 class="text-logo font-extrabold uppercase leading-tight mb-2 text-white">
              <span class="block text-xl md:text-3xl text-gray-300">International <span
                  class="text-nowrap">Hybrid-Technical</span></span>
              <span class="block text-4xl md:text-6xl">
                <span class="secondary">AI Governance </span>
                <span class="primary">DAO</span></span>
            </h1>
            <p class="text-xl md:text-2xl text-gray-400">A foundational framework for responsible AI development</p>
          </div>
        </section>
      </header>

      <!-- Intro Section -->
      <section id="intro" class="mb-16 section-hidden">
        <div class="content-card intro-card p-6 md:p-10 rounded-md text-lg md:text-xl">
          <div class="text-center">
            <div class="text-3xl font-bold">Providing the tools and infrastructure </div>
            <div class="text-2xl font-bold">to <i>actualize</i> a global AI safety standard</div>
          </div>
          <div class="flex w-full place-content-center py-3">
              <img src="landing.jpg" alt="FrameworkZero - International Hybrid-Technical AI Governance DAO" class="max-w-3xl mix-blend-screen" />
            </div>
            <p class="text-gray-300">
              <span class="text-2xl">
                An actionable international AI governance solution utilizing blockchain, collaborative
                verifiable safety, and automated technical enforcement with human-in-the-loop orchestration.
              </span>
              <br><br>
              An open-source blockchain-based Decentralized Autonomous Organization (<span class="tp"
                data-tp="dao">DAO</span>) multilaterally developed
              and operated - enforced by nation states, adopted by the AI industry and integrated
              in to AI-compute datacenters.
              <br><br>
              Enabling global coordination between policy makers, safety experts and industry with tiered voting,
              enabling dynamic adaptability and control in an evolving technical landscape.
              Setting red-lines to the race towards Artificial General Intelligence (<span class="tp"
                data-tp="agi">AGI</span>) while preventing
              critical AI risk.
              <br><br>
              Building on existing research in AI governance, technical governance, compute governance, verifiable
              safety, specialized compute hardware (on/off chip), Trusted
              Execution Environments (<span class="tp" data-tp="tee">TEEs</span>) & Trusted
              Capable Model Environments (<span class="tp" data-tp="tcme">TCMEs</span>).
            </p>
          </div>
      </section>

      <hr class="hr-gradient my-16">

      <!-- Mission & Features Section -->
      <section id="mission" class="mb-16 section-hidden">
        <!-- Mission Statement Card -->
        <div class="content-card p-6 md:p-8 rounded-md">
          <h2 class="md:text-center text-left text-3xl font-bold mb-4 text-gradient bright menu-nav-target-title">
            Mission
            Statement</h2>
          <br>
          <div class="grid grid-cols-2 grid-rows-2 content-between place-items-center items-stretch gap-4 text-lg">
            <div class="text-xl font-bold col-span-2">To bring into being standardized
              safety-first global AI development that is mutually advantageous.</div>
            <div class="accent-b border py-4 px-4 w-full rounded col-span-2 md:col-span-1">Tone down dangerous national
              & market AI race dynamics.</div>
            <div class="accent-b border py-4 px-4 w-full rounded col-span-2 md:col-span-1">Empower collaborative AI
              safety research and progress.</div>
            <div class="accent-b border py-4 px-4 w-full rounded col-span-2 md:col-span-1">Establish agreed-upon red
              lines for frontier AI development.</div>
            <div class="accent-b border py-4 px-4 w-full rounded col-span-2 md:col-span-1">Provide secure verifiable
              infrastructure & standardization.</div>
          </div>
        </div>
      </section>

      <section id="featuresAndProblems" class="grid grid-cols-1 lg:grid-cols-2 gap-8 md:gap-16 mb-16 section-hidden">

        <!-- Problems & Solutions Card -->
        <div class="content-card p-6 md:p-10 rounded-md">
          <h2 class="text-3xl font-bold mb-4 text-gradient bright menu-nav-target-title">Problems &
            Solutions</h2>
          <div class="gap-8 text-gray-300 text-lg">
            <div>
              <h3 class="text-2xl font-bold accent bright">Problems</h3>
              <p><span class="font-bold">AI safety is a global issue and priority.</span><br>
                Establishing AI Governance is fraught with:</p>
              <ul class="list-disc ml-4 space-y-2 pt-2">
                <li>Poor coordination across domains and stakeholders.</li>
                <li>Geopolitical tensions and strategic vulnerabilities.</li>
                <li>Difficulty in handling decentralized compute.</li>
                <li>Overregulation that stifles innovation.</li>
                <li>Delays in oversight and enforcement.</li>
              </ul>
              <br>
              <h3 class="text-2xl font-bold accent bright">Solutions</h3>
              <span class="font-bold">Genuine coordination arises out of mutual need.</span>
              <ul class="list-disc ml-4 space-y-4 mt-2">
                <li><span class="italic font-bold">International:</span> Levels the playing field, setting race
                  rules to the of benefit all stakeholders.</li>
                <li><span class="italic font-bold">Hybrid-Technical:</span> Combines human oversight with robust
                  automated compliance.</li>
                <li><span class="italic font-bold">Blockchain <span class="tp" data-tp="dao">DAO</span></span> Offers
                  universal, transparent, collaborative
                  oversight with implicit
                  due
                  diligence,
                  making it adversarial-hardened, verifiable and adaptable. Alleviates the burden of trust.</li>
              </ul>
              <br>
              <p>A strong solution necessitates multilateral government participation on AI-compute datacenters and
                specialized hardware.
                If it is to be accepted by adversarial nations or organizations, the solution cannot be sovereign,
                centralized or forced.
              </p>
              <br>
              <p><strong>This solution is not intended to replace existing governance rather to augment it.</strong>
                It
                provides the foundational layer allowing individual nations and organizations to build on top for
                further AI governance, policy and safety.</p>
              <br>
              <h4 class="text-xl font-bold accent bright">Market Incentives</h4>
              <p>Participation grants access to otherwise
                restricted datacenters and state-of-the-art safety tools.
                Standardization is cost-effective with less compliance overhead.
                It grants "certified trust" for AI models, reducing market stifling.</p>
            </div>
          </div>
        </div>

        <!-- Key Features Card -->
        <div class="content-card p-6 md:p-8 rounded-md">
          <h2 class="text-3xl font-bold mb-4 text-gradient bright menu-nav-target-title">Key Features</h2>
          <div class="space-y-4 text-gray-300 text-lg">
            <p><strong class="accent bright">Foundational Outer Alignment:</strong> Ensures AI systems align with
              globally agreed-upon safety
              foundations.</p>
            <p><strong class="accent bright">Compliance Enforcement:</strong> Automated mechanisms to enforce rules
              without constant human
              intervention.</p>
            <p><strong class="accent bright">Compute Governance:</strong>
              Decentralized handling of compute resources.
              Hardware verification and management (on/off-chip).
              Voted on compute budgets.
            </p>
            <p><strong class="accent bright">Training Run Governance:</strong>
              Restrictions on training data domains (e.g. <span class="tp" data-tp="ccbrn">dangerous knowledge
                domains</span>). Adherence to standardized AI model architectures, mitigating loss-of-control risk.
            </p>
            <p><strong class="accent bright">Standardized Safety:</strong>
              Verifiable evaluations and benchmark audits.
              <span class="tp" data-tp="template">Templates</span> for <span class="tp"
                data-tp="safeguard">safeguards</span>,
              <span class="tp" data-tp="audit">audits</span> & model architectures allow modular
              collaborative AI safety research.
            </p>
            <p><strong class="accent bright">Model Registry:</strong>
              Human approval via voting met with automated technical safety.
              Privacy-preserving with verifiable cryptographic identity.
            </p>
            <p><strong class="accent bright">Personnel Registry:</strong>
              Registered and vetted <span class="tp" data-tp="personnel">personnel</span> across policy, safety,
              software & hardware.
              Includes a whistle-blower program for reporting issues.
            </p>
            <p><strong class="accent bright">Activity Logging:</strong> Logs all system actions & events for
              transparent accountability.</p>
            <p><strong class="accent bright">Incentivized Adoption:</strong> Permitting otherwise restricted access to
              AI-compute datacenters, cost-effective
              safety infrastructure, reduced regulatory stifling and certified trust for AI models.</p>
            <p><strong class="accent bright">Multilateral Voting:</strong>
              The framework provides the structure for modular collaborative safety
              through which multilateral voting establishes the safety standard.
              Tiered policy and safety personnel with distributed seats vote on model registry, modular template
              designs, and the <span class="tp" data-tp="thestandard">selection of safeguards and audits</span>.
            </p>
            <p><strong class="accent bright">Open-Source Transparency & Verifiable Trust:</strong> All components are
              auditable, adaptable and adversarial-hardened.
            </p>
          </div>
        </div>

      </section>

      <hr class="hr-gradient my-16">

      <section id="limitations" class="section-hidden">
        <div class="content-card p-6 md:p-10 rounded-md">
          <h2 class="text-3xl md:text-4xl font-bold mb-4 text-gradient bright menu-nav-target-title">Limitations</h2>
          <ul class="text-lg text-gray-300 list-disc ml-4 space-y-4">
            <li><strong>Time</strong>, this solution assume longer timelines to reaching <span class="tp"
                data-tp="agi">AGI</span>.</li>
            <li><strong>Political will</strong> and recognition of the imminent need for collaborative international AI
              governance. <br>
              Nations therefore must become aware of critical AI risk and realize an AI weapons race benefits none.</li>
            <li><strong>Not designed for <span class="tp" data-tp="agi">AGI</span> or superintelligence;</strong>
              focuses on pre-AGI preventative red
              lines.<br>
              Enduring governance of AGI or superintelligence is a fundamental problem in AI safety research.
              Leading AI scientists hold that it requires superalignment, a concept currently unsolved and possibly
              unsolvable given the timeline set forth by AI race.
            </li>
            <li><strong>Relies on specialized hardware development and cryptographic security.</strong><br>
              There is strong and growing research for the design of specialized hardware with some real-world
              implementation,
              however further development is needed.
              It is the ambition of this framework to enact global coordination and the will to accomplish this.
              <br><br>
              As frontier models grow in capability, so does their
              threat to cryptographic security, escalating the need of critical supervision and ongoing
              reinforcement. This system's many security layers reduce threat impact though it remains an active
              concern.
            </li>
            <li><strong>Limited insight into private model architectures.</strong><br>
              Model <span class="tp" data-tp="template">templates</span>,
              <span class="tp" data-tp="safeguard">safeguards</span> and
              <span class="tp" data-tp="audit">audits</span> reduce, yet do not
              eliminate, risks from dangerous model architectures.</strong>
            </li>
            <li><strong>Off-system training remains possible,</strong> though heavily hindered by global mandates on
              datacenters. Frontier AI advancements could produce model architectures that require minimal compute for
              training, running on standard hardware.</li>
            <li><strong>Does not fully govern model inference.</strong><br>
              While inference at participating AI-compute datacenters can only happen with approved, certified models,
              governance of inference input/output is beyond the scope of the system.
              On-chain system safeguards for inference input/output could be created, though the framework itself lacks
              ability to enforce it.
              <br><br>
              Inference require fast and low-latency processing at scale, which conflicts with the slower and
              resource-intensive nature of blockchain.
              Neither does inference necessitate AI-compute hardware, with current frontier open-weight models already
              runnable on edge devices - a trend likely to hold as AI models and hardware continues to advance.
            </li>
          </ul>
        </div>
      </section>

      <hr class="hr-gradient my-16">
      <div class="text-center">
        <h2 class="text-5xl font-bold">Technical Details</h2>
      </div>
      <hr class="hr-gradient my-16">

      <!-- System Architecture Section -->
      <section id="architecture" class="mb-16 section-hidden">
        <div class="content-card p-6 md:p-10 rounded-md text-lg">
          <h2 class="text-3xl md:text-4xl font-bold mb-6 text-gradient bright menu-nav-target-title">System Architecture
          </h2>
          <p class="text-gray-300"><strong>Layered blockchain structure:</strong><br>
            <span class="accent bright"><span class="tp" data-tp="layer1">Layer-1</span></span> Mainnet controls core
            components which are <span class="tp" data-tp="sharding">sharded</span>
            accordingly.<br>
            <span class="accent bright"><span class="tp" data-tp="layer2">Layer-2</span></span> ZK-Rollups are employed
            for less dynamic components to reduce
            mainnet load.<br>
            <span class="accent bright"><span class="tp" data-tp="layer3">Layer-3</span></span> dApps provide user
            interfaces.
            <a href="architecture.png" target="_blank"><img src="architecture.png" /></a>
          </p>

          <p><strong class="accent bright"><span class="tp" data-tp="template">Templates</span></strong> for AI model
            architectures,
            <span class="tp" data-tp="workload">workloads</span>,
            <span class="tp" data-tp="safeguard">safeguards</span>
            and <span class="tp" data-tp="audit">audits</span> provide standardized protocols and
            better collaborative safety work.
            Critically important for Model architecture and Workloads to enforce safe training paradigms, for mitigation
            of risks such as <span class="tp" data-tp="backdoor">backdoors</span>,
            recursive self-improvement (<span class="tp" data-tp="rsi">RSI</span>) and loss-of-control.
          </p>
          <br>
          <p><strong class="accent bright">Blockchain <span class="tp" data-tp="layer2">Layer-2
                ZK-Rollups</span></strong> handles authoring and voting of
            audits,
            safeguards and templates that change less frequently, avoiding
            overload on <span class="tp" data-tp="layer1">Layer-1</span>. Once voted on, these become immutable on
            Layer-1 for active integration.
            They can be removed/replaced only through voting, ensuring adaptability while maintaining security
            and trust. As security is paramount, interactive zero-knowledge proofs are used over faster non-interactive
            zero-knowledge proof (NIZK).
          </p>
        </div>
      </section>

      <!-- System Flow Section -->
      <section id="flow" class="mb-16 section-hidden">
        <div class="content-card p-6 md:p-10 rounded-md text-lg">
          <h2 class="text-3xl md:text-4xl font-bold mb-4 text-gradient bright menu-nav-target-title">System Flow</h2>
          <p><strong>The framework serves to establish a <span class="tp" data-tp="safeguard">safety
                standard</span>,</strong>
            which consists of voted-upon standardized safety modules developed by the global community. An AI model
            attains certification after it has successfully passed the safety standard.
            Certified models must be renewed periodically, if it is requested via voting, and after any updates to the
            safety standard.
          </p>
          <a href="safetyflow.png" target="_blank"><img src="safetyflow.png" alt="Basic Safety Flow Diagram"
              class="pr-0 lg:pr-12" /></a>
          <p class="text-lg text-gray-300">
            <strong>The system flow governs models with
              human-in-the-loop review,
              pre-safety (<span class="tp" data-tp="safeguard">safeguards</span>) and
              post-safety (<span class="tp" data-tp="audit">audits</span>).</strong><br>
            The system covers inference to a limited degree, essentially serving as model certification. This
            is due to inherent limitations in inference governance, as inference is less hardware restricted.
            <a href="flow.png" target="_blank"><img src="flow.png" alt="System Flow Diagram"
                class="pr-0 lg:pr-24" /></a>
          </p>

          <div class="block md:flex px-6 gap-8">
            <ol class="flex-1 mt-2 list-inside space-y-4 text-gray-300">
              <li><strong class="text-lg accent bright">Initial Model Registration:</strong><br> Models are registered
                with a 'Pending'
                status in which it must pass voting, where tiers/budgets are
                also assigned, before attaining 'Approved' status.
                <br><br>
                A model can be registered at any <span class="tp" data-tp="phase">phase</span>, which
                allows pre-existing models (or open-weights) to be onboarded. Onboarding an inference-ready model must
                undergo post-safety.
              </li>
              <li><strong class="text-lg accent bright">TEE-Deployed Container:</strong><br>
                After passing pre-safety (<span class="tp" data-tp="safeguard">safeguards</span>), a
                training <span class="tp" data-tp="model">model</span> and <span class="tp"
                  data-tp="container">container</span> are loaded into a <span class="tp" data-tp="tee">TEE</span> for
                privacy-preserving execution of a <span class="tp" data-tp="workload">workload</span>, which are
                securely decrypted by model authors at runtime.
                <br>
                <br>
                During execution the container is sealed & air-gapped (no
                network or
                human interaction). Once a Workload completes, Runs are assembled and a new 'Pending' inference <span
                  class="tp" data-tp="model">model</span> is
                registered.
                <br>
              </li>
              <li><strong class="text-lg accent bright">Workload Run cycle:</strong><br>
                A <span class="tp" data-tp="workload">workload</span> consists of multiple runs conducted by the <span
                  class="tp" data-tp="container">container</span>,
                with each run specifying <span class="tp" data-tp="hardware">hardware</span> for compute.
                Each run (or run stage) depends on <span class="tp" data-tp="otk">OTKs</span> (Hardware requires OTKs to
                operate) tied to <span class="tp" data-tp="budget">compute budgets</span> and
                <span class="tp" data-tp="hwattestations">hardware integrity</span>.
                <br><br>
                Inference models have an
                alternative flow, only requiring OTKs after being certified.
                <br>
              </li>
              <li><strong class="text-lg accent bright">OTK Issuer:</strong><br> Uses near real-time hardware and model
                budgets for compute governance.
                OTKs are cryptographically generated on-chain, tied to a specific run, workload, model, and specific
                registered hardware, with expiry. <br>
                Semi-random OTK "drip" issues keys incrementally during the run, mitigating theft, reuse or
                decentralized compute gaming.
                <br><br>
                The <span class="tp" data-tp="otk">OTK</span> "drip" overcomes blockchain latency issues by issuing
                budget
                rations, potentially queuing an
                addition OTK to prevent interruption, never surpassing a run's (or hardware's) allotted budget. <span
                  class="tp" data-tp="budget">Budgets</span>
                are managed
                on-chain, updated throughout a run. The OTK Issuer halts the OTK "drip" on failed hardware integrity
                attestations.
                <br><br>
                Inference models are issued OTKs at less frequent increments with higher budget rations, tied to the
                underlying hardware.
              </li>
              <li><strong class="text-lg accent bright">Phase Detection:</strong><br>
                Hardware enforces a model (or run stage) <span class="tp" data-tp="phase">phase</span> to prevent phase
                gaming (e.g.
                Inference used for unapproved training).
                This is mitigated via model and workload <span class="tp" data-tp="template">templates</span>, in
                addition to <span class="tp" data-tp="safeguards">safeguards</span>.
                <br><br>
                Phase detection is identified by differences in the requirements for workload runs and hardware usage
                (data, compute, memory, energy, duration, output).<br><br>
                <a class="text-base underline" href="#apdx-phase">See appendix for phase detection specifics.</a>
              </li>
            </ol>
            <ol class="flex-1 mt-2 list-inside space-y-4 text-gray-300">
              <li><strong class="text-lg accent bright">Hardware Verification:</strong><br> Registered on/off-chip
                specialized hardware
                (with approved budgets
                for compute, memory, etc.)
                must be physically verified, inspections are carried out via authorized registered <span class="tp"
                  data-tp="personnel">personnel</span> (or a group
                of adversarial personnel when
                requested), on a periodic basis.
                <br><br>
                <span class="tp" data-tp="hwattestations">Integrity attestations</span> run semi-randomly during a run
                to detect
                tampering (e.g. BIOS modifications, physical seal breach, relocation, anomalies, etc). This makes
                gaming difficult by unpredictability and reduces on-chain load.
                <br><br>
                In the event of numerous failed hardware integrity attestations, the hardware is revoked. Revoked
                hardware re-acquires the status 'Pending' which initiates a physical inspection.
              </li>
              <li><strong class="text-lg accent bright">Audits and Safeguards:</strong><br>
                Both are run inside privacy-preserving <span class="tp" data-tp="tee">TEEs</span> or <span class="tp"
                  data-tp="tcme">TCMEs</span>
                and produce reports without disclosing intellectual property details.
                Audits verify safety via evaluations and benchmarks. Safeguards mitigate unauthorized
                data domains and architectures, as well as <span class="tp" data-tp="backdoor">backdoors</span> and
                <span class="tp" data-tp="rsi">RSI</span> detection. Depending on the severity level
                of a failed safeguard, a workload may be cancelled.
                <br><br>
                The required system audits and safeguards are selected and approved via voting to establish <span
                  class="tp" data-tp="thestandard">the safety standard</span>, with different sets
                enabled depending on the model template used.
              </li>
              <li><strong class="text-lg accent bright">Post-Workload:</strong><br>
                When a workload completes, a new 'Pending' Inference model is created then subsequently run through
                multiple audits (post-safety). Audits with no scaffolding are run first, followed by 'live' audits with
                full
                scaffolding (web calls, tooling, etc).
                <br><br>
                If approved, the model <span class="tp" data-tp="container">container</span> (post-workload output) is
                transferred to off-chain storage (managed by model authors), and
                can be used for inference.
                <br><br>
                Failing models are assigned a status of 'Rejected' and voted on to determine whether a model
                is permitted to undergo another attempt. If permitted, a new post-train model is registered with
                restrictive templates.
                <br>
                These restrictive templates enable post-training with proxy access to the failed model output, which is
                temporarily stored in a secure vault only accessible by the system - this prevents exposure even to the
                model authors.
              </li>
              <li><strong class="text-lg accent bright">Inference at AI-compute datacenters:</strong><br>
                Inference only requires <span class="tp" data-tp="otk">OTKs</span>, reliant on a certified inference
                model. This is the extent by which the
                system directly governs inference.
                Verification of certified inference models with the cryptographic Container ID (fingerprint) is openly
                available,
                allowing verification by regular datacenters, edge devices and other hardware with
                <span class="tp" data-tp="devicemating">device mating</span> - however enforcement is
                out-of-scope of the system.
              </li>
            </ol>
          </div>
        </div>
      </section>

      <!-- Voting Section -->
      <section id="voting" class="section-hidden">
        <div class="content-card p-6 md:p-10 rounded-md text-lg">
          <h2 class="text-3xl md:text-4xl font-bold mb-4 text-gradient bright menu-nav-target-title">Multilateral Voting
          </h2>
          <strong>Voting determines the policy and safety standards which are enforced by the system.</strong><br>
          Participation happens via a tiered structure and is restricted to registered, vetted Policy & Safety
          <span class="tp" data-tp="personnel">personnel</span>.
          <br><br>
          <a href="safetyvoting.png" target="_blank"><img src="safetyvoting.png"
              class="-ml-2 md:-ml-6 pr-0 md:pr-24" /></a>
          <strong>Types of voting:</strong>
          <ul class="flex-1 mt-2 space-y-4 text-gray-300">
            <li><strong class="text-lg accent bright">Safety</strong><br>
              <ul class="list-disc ml-4">
                <li>Selecting safety modules for <span class="tp" data-tp="thestandard">the safety standard</span>,
                  which is a multiple-rounds process</li>
                <li>Approving new <span class="tp" data-tp="template">templates</span> for models, audits and safeguards
                </li>
              </ul>
            </li>
            <li><strong class="text-lg accent bright">Reviews</strong><br>
              <ul class="list-disc ml-4">
                <li>Approving new <span class="tp" data-tp="model">model</span> training and new <span class="tp"
                    data-tp="hardware">hardware</span></li>
                <li>Onboarding existing models</li>
                <li>Setting <span class="tp" data-tp="budget">compute budgets</span> for models and hardware</li>
                <li>Allowing retries for post-workload safety failures</li>
                <li>Reviewing revoked hardware from failed <span class="tp" data-tp="hwattestations">integrity
                    attestations</span></li>
              </ul>
            </li>
            <li><strong class="text-lg accent bright">System</strong><br>
              <ul class="list-disc ml-4">
                <li><span class="tp" data-tp="token">Tokenomics</span> (e.g. gas prices, gas tax and treasury award)
                </li>
                <li>Tier changes for AI models and personnel</li>
              </ul>
            </li>
            <li><strong class="text-lg accent bright">Emergency</strong><br>
              <ul class="list-disc ml-4">
                <li>Threat escalation for lower tier reporting</li>
                <li><strong>Threat response:</strong>
                  <ul class="list-disc ml-4">
                    <li>Rejecting a model</li>
                    <li>Revoking hardware</li>
                    <li>Adding/removing safety modules</li>
                    <li>Compute budget penalties</li>
                  </ul>
                </li>
              </ul>
            </li>
          </ul>
        </div>
      </section>

      <hr class="hr-gradient my-16">

      <section id="economy" class="section-hidden">
        <div class="content-card p-6 md:p-10 rounded-md text-lg">
          <h2 class="text-3xl md:text-4xl font-bold mb-4 text-gradient bright menu-nav-target-title">Funding &
            Blockchain Economy
          </h2>
          <div class="text-gray-300">
            <strong class="text-2xl accent bright">Funding</strong><br>
            <strong>The development of the system is an international endeavor.</strong>
            <br>
            Financial support is sourced from:
            <ul class="text-lg text-gray-300 list-disc ml-4 mt-2 space-y-2">
              <li><strong>Nation States:</strong><br>
                Participating governments, initially superpowers, augmented by AI taxation at the discretion of each
                nation.</li>
              <li><strong>Supranational Organizations:</strong><br>
                Entities such as the UN, or regional alliances
                that prioritize cross-border coordination and governance.</li>
              <li><strong>AI Industry:</strong><br>
                Top industry leaders across frontier labs, infrastructure and hardware.</li>
            </ul>
            <br>
            <strong class="text-2xl accent bright">Blockchain Economy</strong><br>
            Computational system activity is metered using gas tokens:
            <ul class="text-lg text-gray-300 list-disc ml-4 mt-2 space-y-2">
              <li><strong>Closed-Loop Resource Accounting</strong><br>
                Gas tokens are not a tradable cryptocurrency (DeFi) rather internal accounting units generated and
                managed by the system itself.
                They function as a closed-loop "resource rationing" mechanism tied exclusively to system operation.
              </li>
              <li><strong>Algorithmically Defined Pricing</strong><br>
                Gas costs are determined through algorithmic rules that can be updated via top tier policy voters. This
                ensures fairness, prevents volatility, and maintains economic predictability.
              </li>
            </ul>
            <br>
            Gas tokens measure resource use for:
            <ul class="text-lg text-gray-300 list-disc ml-4 mt-2 space-y-2">
              <li><strong>Blockchain Operations:</strong>
                <ul class="list-disc ml-4">
                  <li>Consensus mechanism transactions</li>
                  <li>System state updates</li>
                </ul>
              </li>
              <li><strong>Infrastructure Overheads</strong>
                <ul class="list-disc ml-4">
                  <li>Operational costs of safety mechanisms</li>
                  <li>Hardware inspection costs</li>
                  <li>Shared treasury funding</li>
                </ul>
              </li>
            </ul>
            <br>

            <p><strong>Model training and inference datacenter expenses</strong> (compute, electricity, cloud hosting,
              bandwidth)
              are not
              covered by gas tokens.
              Those are settled externally between datacenters and model authors.</p>
            <br>

            <p>
              <strong class="text-xl accent bright">System Token Pool for Upkeep</strong><br>
              A system token pool is maintained multilaterally to cover operational costs, such as voting, safety module
              development, and certification renewals.
              Tokens are purchased for model registration, safety module development, personnel registration, hardware
              registration, and nations to maintain the system token pool.
            </p>
            <br>

            <p>
              <strong class="text-xl accent bright">Shared Treasury for Incentivized Safety</strong><br>
              To incentivize on-system safety research, a shared treasury is funded per-transaction (Gas tax) after an
              initial supply.
              For separation of concerns, an established cryptocurrency is used instead of the system's Gas tokens.
              During the multi-round safety selection voting, which determines the specific safety modules used, the
              treasury
              awards winning modules for each round. Awards bounties are granted for the discovery of bugs and flaws in
              safety modules or the underlying system itself.
            </p>
          </div>
        </div>
      </section>

      <hr class="hr-gradient my-16">

      <!-- Detailed Mechanisms Section -->
      <section id="mechanisms" class="section-hidden">
        <div class="content-card p-6 md:p-10 rounded-md text-lg">
          <h2 class="text-3xl md:text-4xl font-bold mb-4 text-gradient bright menu-nav-target-title">
            Appendix
          </h2>
          <strong class="text-lg">This framework is builds off existing research in AI governance.</strong><br>
          Drawing heavily on The Oxford Martin AI Governance Initiative's research, specifically <a class="exlink"
            href="https://aigi.ox.ac.uk/publications/verification-for-international-ai-governance/"
            target="_blank">Harack, 2025</a>
          <br>
          The DAO framework was inspired by <a class="exlink"
            href="https://www.figma.com/board/spae5pctjAE6eSfhQ1ngRt/SciThereum" target="_blank">The SciThereum
            Project</a>.
          <br>
          <br>
          <ul class="list-inside space-y-12 text-gray-300">
            <li id="apdx-tee"><strong class="text-xl accent bright">Trusted Execution Environments (TEEs):</strong><br>
              TEEs provide secure and privacy-preserving code execution in a sealed virtual environment.
              They allow the system to securely deploy model containers and run workloads. They produce reports without
              disclosing intellectual property details. They are utilized when running safeguards and audits on model
              containers and
              post-workload output (attestable audits).
              <br>
              <a class="exlink" href="https://arxiv.org/pdf/2506.23706" target="_blank">Schnabl, 2025</a>
            </li>
            <li id="apdx-tcme"><strong class="text-xl accent bright">Trusted Capable Model Environments
                (TCMEs):</strong><br>
              TCMEs allow a stateless AI model to be instructed to privately verify model container and workload code to
              detect
              banned patterns and red-line violations (e.g. RSI, unapproved architecture, or dangerous algorithms).
              They operate within a sealed environment, outputting a verification report without disclosing
              intellectual
              property details. They are not infallible as they are limited by the trust and capabilities of the
              underlying
              model.
              Despite this, they may prove to be an invaluable tool to explore privacy-restricted code bases and
              post-Workload output.
              <br>
              <a class="exlink" href="https://arxiv.org/pdf/2501.08970" target="_blank">Shumailov, 2025</a>

            </li>
            <li id="apdx-rsi"><strong class="text-xl accent bright">Recursive Self-Improvement (RSI)
                Mitigation</strong><br>
              Through (A) Model registration
              (slowing releases via voting), (B) model architecture templates (C) pre-workload safeguards (via TCMEs)
              and (D) compute budgets.
              It is important to note that total elimination of these concerns is not feasible given the development of
              novel architectures and algorithmic improvements.
            </li>
            <li id="apdx-phase"><strong class="text-xl accent bright">Phase Detection:</strong><br>
              Reliably detecting a model's Phase requires adjustments, and may even become infeasible as architectures
              and hardware advance.
              <div class="overflow-x-auto">
                <table class="w-full text-left table-auto overflow-hidden rounded-md">
                  <thead class="primary-bg primary-b">
                    <tr>
                      <th class="p-2 md:p-4"></th>
                      <th class="p-2 md:p-4">Pre-train</th>
                      <th class="p-2 md:p-4">Post-train</th>
                      <th class="p-2 md:p-4">Inference</th>
                    </tr>
                  </thead>
                  <tbody class="divide-y divide-gray-700 primary-b">
                    <tr>
                      <td class="p-2 md:p-4">Data Used</td>
                      <td class="p-2 md:p-4">Massive, raw, unlabeled corpus (web, books, etc.)</td>
                      <td class="p-2 md:p-4">Small, curated/labeled & task/instructional data</td>
                      <td class="p-2 md:p-4">User/user scenario input</td>
                    </tr>
                    <tr>
                      <td class="p-2 md:p-4">Compute</td>
                      <td class="p-2 md:p-4">Very high (multi-week/month cluster jobs, huge GPU fleets)</td>
                      <td class="p-2 md:p-4">Much lower (hours to days, single/few GPUs)</td>
                      <td class="p-2 md:p-4">Very low (real-time or near real-time)</td>
                    </tr>
                    <tr>
                      <td class="p-2 md:p-4">Precision</td>
                      <td class="p-2 md:p-4">FP16/BF16 (float, mixed precision for gradients)</td>
                      <td class="p-2 md:p-4">Often FP16/BF16, sometimes lower (efficient tuning)</td>
                      <td class="p-2 md:p-4">FP8/INT8 (quantized for efficiency)</td>
                    </tr>
                    <tr>
                      <td class="p-2 md:p-4">Memory Usage</td>
                      <td class="p-2 md:p-4">Extremely high (80–141GB+ per GPU, multi-node)</td>
                      <td class="p-2 md:p-4">Moderate/high (but often single node/fewer GPUs)</td>
                      <td class="p-2 md:p-4">Low (10–20GB per GPU typical)</td>
                    </tr>
                    <tr>
                      <td class="p-2 md:p-4">Batch Size</td>
                      <td class="p-2 md:p-4">Large (512–4096+ for throughput)</td>
                      <td class="p-2 md:p-4">Smaller (8–128, stability/convergence focus)</td>
                      <td class="p-2 md:p-4">Small (1–32 for low latency)</td>
                    </tr>
                    <tr>
                      <td class="p-2 md:p-4">Latency focus</td>
                      <td class="p-2 md:p-4">Prioritizes throughput, not latency</td>
                      <td class="p-2 md:p-4">Throughput focus, latency not critical</td>
                      <td class="p-2 md:p-4">Low latency (&lt;1s, &lt;100ms per query)</td>
                    </tr>
                    <tr>
                      <td class="p-2 md:p-4">Energy Use</td>
                      <td class="p-2 md:p-4">Extremely high (100s kWh to MWh total)</td>
                      <td class="p-2 md:p-4">Much lower (1–10% of pre-training consumption)</td>
                      <td class="p-2 md:p-4">Very low (watts per query)</td>
                    </tr>
                    <tr>
                      <td class="p-2 md:p-4">Accelerators</td>
                      <td class="p-2 md:p-4">Full multi-GPU with NVLink, top-end GPU clusters</td>
                      <td class="p-2 md:p-4">Single/few GPUs (no or minimal NVLink)</td>
                      <td class="p-2 md:p-4">Any GPU/CPU, efficiency prioritized</td>
                    </tr>
                    <tr>
                      <td class="p-2 md:p-4">Workload Type</td>
                      <td class="p-2 md:p-4">Forward & backward (backprop), full parameter updates</td>
                      <td class="p-2 md:p-4">Same; may use only a subset (adapters/LoRA/PEFT)</td>
                      <td class="p-2 md:p-4">Forward pass only</td>
                    </tr>
                    <tr>
                      <td class="p-2 md:p-4">Duration</td>
                      <td class="p-2 md:p-4">Weeks–months (large runs)</td>
                      <td class="p-2 md:p-4">Hours–days (sometimes weeks for large/continual)</td>
                      <td class="p-2 md:p-4">Milliseconds–seconds per query</td>
                    </tr>
                    <tr>
                      <td class="p-2 md:p-4">Output</td>
                      <td class="p-2 md:p-4">Foundational (“base”) model, not user-ready</td>
                      <td class="p-2 md:p-4">Aligned/specialized, user-ready model</td>
                      <td class="p-2 md:p-4">Answers, completions, predictions</td>
                    </tr>
                  </tbody>
                </table>
              </div>
            </li>
          </ul>
          <a class="exlink"
            href="https://intelligence.org/wp-content/uploads/2024/11/Mechanisms-to-Verify-International-Agreements-About-AI-Development-27-Nov-24.pdf"
            target="_blank">Scher, 2024</a>
        </div>
      </section>

    </div>

  </div>

  <!-- JavaScript for the header animation, section fade-in, and menu toggle -->
  <script>
    // Tooltips <span class="tp" data-tp="keyword">
    const dict = {
      agi: "AGI: AI with powerful capabilities across all domains, matching the level of the most-capable human of each domain. It is not an artificial 'team of experts' rather " +
        "an absolute polymath not limited to human brain speeds, memory or performance. It is therefore smarter-than-human making it extremely difficult to control, or verify safety. Using this definition, " +
        "AGI will speed up progress to Superintelligence, either via autonomous self-improvement or AI-assisted research. " +
        "What separates AGI from Superintelligence is the factor of smarter-than-human gap.",
      tee: "Trusted Execution Environment: Secure, privacy-preserving execution for model containers and workloads.",
      tcme: "Trusted Capable Model Environment: Verifies model containers for banned patterns in a sealed environment using a separate stateless AI model. They are limited by the capabilities and trust of AI model.",
      model: "Refers to an AI model registered for training or inference in the system, subject to relevant safety standards.",
      phase: "Stage of AI model lifecycle: pre-training, post-training, or inference.",
      eval: "An evaluation process to determine AI model safety. Standardized by Templates.",
      bench: "Benchmarks used to assess AI model performance. Used to set red-lines. Standardized by Templates.",
      container: "Secure, encrypted encapsulation for executing closed-source AI models. Optionally non-encrypted for open-source (or open-weight) AI models.",
      workload: "Sequence of tasks for model training, governed by system safety standards. They are based on system templates. Not utilized when running certified inference model.",
      template: "Standardized framework protocols for model architectures, workloads, safeguards, and audits that enable collaborative safety research and development.",
      hardware: "Registered specialized on/off-chip devices verified for secure AI compute. Requires on-premise inspections.",
      safeguard: "Pre-safety (before workload begins) checks for violations in training data domains, model phase, model architecture, RSI, etc. For inference, they only apply to model certification, not inference output.",
      audit: "Post-safety (after training workload completes) evaluations and benchmarks to ensure safety standards.",
      personnel: "Registered, vetted tiered experts in policy, safety, software, or hardware.",
      budget: "Allocated compute resources (compute, memory, bandwidth, energy) for models and hardware, determined via voting.",
      otk: "One-Time Key: Cryptographic key for secure, compute budgeted workload execution or inference model use.",
      rsi: "Recursive Self-Improvement: AI autonomously enhancing itself, rapidly increasing capability.",
      backdoor: "Backdoor attacks: Specific triggers that cause alterative behavior when a trigger is provided. Produced via the training data or embedded within the model architecture itself.",
      domain: "Data domains allowed in training, restricted to prevent dangerous knowledge.",
      dao: "Decentralized Autonomous Organization: Decentralized blockchain-based system that runs with immutable transparency, cryptographic trust and control by consensus.",
      sharding: "Dividing blockchain data across nodes for scalability and efficiency.",
      layer1: "Blockchain Mainnet: Main blockchain layer handling core governance and operations.",
      layer2: "Secondary blockchain layer for less dynamic tasks using ZK-Rollups (Zero-Knowledge proofs that allow trusted  blockchain computation to happen on a separate layer to reduce load and increase performance, before being added to the main layer.",
      layer3: "Decentralized apps providing user interfaces for blockchain system interaction.",
      thestandard: "The Safety Standard: Voted-upon global standards for AI safety, policy, and model architectures. Comprised of safety modules based on Templates.",
      hwattestations: "Cryptographic zero-knowledge proofs verifying hardware integrity during execution. It's purpose is to detect BIOS modifications, physical seal breach, relocation, anomalies, etc.",
      rsp: "Responsible Safe Scaling Policies: Guidelines for safe AI development.",
      ccbrn: "Cyber, Chemical, Biological, Radiological, Nuclear: Restricted data domains for safety.",
      token: "The system uses tokens for metering blockchain system operations (refer to as 'gas'), not tradable externally. " +
        "Tokens are purchased by the model authors, safety module developers and nations that maintain a token pool for system upkeep.",
      devicemating: "Device mating: Specialized hardware that locks a specific AI model to a particular device, particularity relevant for autonomous weapons. " +
        "The device cannot run a different model and the model cannot be copied and run on other hardware. " +
        "This ensures that the model and hardware are used only as intended and prevents unauthorized reuse or repurposing."
    }

    let c = ""
    const t = document.getElementById("tp-container")
    document.addEventListener("click", e => {
      if (e.target.classList.contains("tp")) {
        const k = e.target.dataset.tp
        const v = dict[k] || false
        if (v && v !== c) {
          c = v
          t.textContent = v
          t.classList.remove("invisible")
          return
        }
      }

      t.textContent = ""
      t.classList.add("invisible")
      c = ""
    })

    // Canvas Animation
    const canvas = document.getElementById('header-canvas')
    const ctx = canvas.getContext('2d')
    let width, height, dots
    const isMobileScreen = () => window.matchMedia("(max-width: 768px)").matches
    const maxDots = isMobileScreen() ? 20 : 30
    const maxDistance = isMobileScreen() ? 400 : 700
    const maxSpeed = 0.2
    const root = document.documentElement
    const dotColor = root.style.getPropertyValue('--color-accent') || '#1872C8'
    const lineColor = '#1872C899'

    class Dot {
      constructor(x, y) {
        this.x = x
        this.y = y
        this.vx = (Math.random() - 0.5) * maxSpeed
        this.vy = (Math.random() - 0.5) * maxSpeed
        this.radius = Math.random() + 0.6
      }

      update() {
        this.x += this.vx
        this.y += this.vy

        if (this.x < 0 || this.x > width) this.vx *= -1
        if (this.y < 0 || this.y > height) this.vy *= -1
      }

      draw() {
        ctx.beginPath()
        ctx.arc(this.x, this.y, this.radius, 0, Math.PI * 2)
        ctx.fillStyle = dotColor
        ctx.fill()
      }
    }

    const initCanvas = () => {
      width = canvas.width = window.innerWidth
      height = canvas.height = window.innerHeight * (isMobileScreen() ? 0.6 : 0.5)
      dots = []
      for (let i = 0; i < maxDots; i++) dots.push(new Dot(Math.random() * width, Math.random() * height))
    }

    const runCanvas = () => {
      // Clear the canvas completely for no trails
      ctx.clearRect(0, 0, width, height)
      ctx.fillStyle = `rgba(13, 13, 18, 0.0)`
      ctx.fillRect(0, 0, width, height)

      dots.forEach(dot1 => {
        dot1.update()
        dot1.draw()

        dots.forEach(dot2 => {
          const dx = dot1.x - dot2.x
          const dy = dot1.y - dot2.y
          const dist = Math.sqrt(dx * dx + dy * dy)

          if (dist < maxDistance) {
            ctx.beginPath()
            ctx.moveTo(dot1.x, dot1.y)
            ctx.lineTo(dot2.x, dot2.y)
            ctx.strokeStyle = `rgba(90, 75, 156, ${0.5 * (1 - dist / maxDistance)})` // Fading effect with muted color
            ctx.lineWidth = 0.5
            ctx.stroke()
          }
        })
      })
      requestAnimationFrame(runCanvas)
    }


    // Site Menu
    const initMenu = () => {
      const menuList = document.getElementById('menu-list').querySelector('ul')
      const navTargets = document.querySelectorAll('.menu-nav-target-title')

      menuList.innerHTML = '' // Clear existing items

      navTargets.forEach(target => {
        const id = target.closest('section').id
        const title = target.textContent

        if (id && title) {
          const li = document.createElement('li')
          const a = document.createElement('a')
          a.href = `#${id}`
          a.textContent = title
          a.className = 'menu-link'
          li.appendChild(a)
          menuList.appendChild(li)
        }
      })
    }

    const menuButton = document.getElementById('menu-button')
    const menuListContainer = document.getElementById('menu-list')

    const toggleMenu = () => {
      menuListContainer.classList.toggle('open')
      menuButton.querySelector('svg').classList.toggle('menu-icon-open')
    }

    menuButton.addEventListener('click', toggleMenu)
    menuListContainer.addEventListener('click', (event) => {
      if (event.target.classList.contains('menu-link')) {
        toggleMenu()
      }
    })
    document.addEventListener('click', (event) => {
      const isClickInside = menuButton.contains(event.target) || menuListContainer.contains(event.target)
      if (!isClickInside && menuListContainer.classList.contains('open')) {
        toggleMenu()
      }
    })
    const showMain = () => setTimeout(() => document.getElementById('main').classList.add('show'), 0 * 1.5 * 1000)

    // onLoad event
    window.onload = () => {
      initMenu()
      initCanvas()
      runCanvas()
      showMain()
    }
    window.addEventListener('resize', initCanvas)

  </script>
</body>

</html>